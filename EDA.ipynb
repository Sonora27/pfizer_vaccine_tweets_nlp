{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"vaccination_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1340539111971516416</td>\n",
       "      <td>Rachel Roh</td>\n",
       "      <td>La Crescenta-Montrose, CA</td>\n",
       "      <td>Aggregator of Asian American news; scanning di...</td>\n",
       "      <td>2009-04-08 17:52:46</td>\n",
       "      <td>405</td>\n",
       "      <td>1692</td>\n",
       "      <td>3247</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-20 06:06:44</td>\n",
       "      <td>Same folks said daikon paste could treat a cyt...</td>\n",
       "      <td>['PfizerBioNTech']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1338158543359250433</td>\n",
       "      <td>Albert Fong</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Marketing dude, tech geek, heavy metal &amp; '80s ...</td>\n",
       "      <td>2009-09-21 15:27:30</td>\n",
       "      <td>834</td>\n",
       "      <td>666</td>\n",
       "      <td>178</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-13 16:27:13</td>\n",
       "      <td>While the world has been on the wrong side of ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1337858199140118533</td>\n",
       "      <td>eliüá±üáπüá™üá∫üëå</td>\n",
       "      <td>Your Bed</td>\n",
       "      <td>heil, hydra üñê‚ò∫</td>\n",
       "      <td>2020-06-25 23:30:28</td>\n",
       "      <td>10</td>\n",
       "      <td>88</td>\n",
       "      <td>155</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 20:33:45</td>\n",
       "      <td>#coronavirus #SputnikV #AstraZeneca #PfizerBio...</td>\n",
       "      <td>['coronavirus', 'SputnikV', 'AstraZeneca', 'Pf...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1337855739918835717</td>\n",
       "      <td>Charles Adler</td>\n",
       "      <td>Vancouver, BC - Canada</td>\n",
       "      <td>Hosting \"CharlesAdlerTonight\" Global News Radi...</td>\n",
       "      <td>2008-09-10 11:28:53</td>\n",
       "      <td>49165</td>\n",
       "      <td>3933</td>\n",
       "      <td>21853</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-12-12 20:23:59</td>\n",
       "      <td>Facts are immutable, Senator, even when you're...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>446</td>\n",
       "      <td>2129</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1337854064604966912</td>\n",
       "      <td>Citizen News Channel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Citizen News Channel bringing you an alternati...</td>\n",
       "      <td>2020-04-23 17:58:42</td>\n",
       "      <td>152</td>\n",
       "      <td>580</td>\n",
       "      <td>1473</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-12-12 20:17:19</td>\n",
       "      <td>Explain to me again why we need a vaccine @Bor...</td>\n",
       "      <td>['whereareallthesickpeople', 'PfizerBioNTech']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7140</th>\n",
       "      <td>1371093686088568837</td>\n",
       "      <td>Oezguer Yalcin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Philosophy, public health\\nPerspectives on #SA...</td>\n",
       "      <td>2021-01-12 10:38:24</td>\n",
       "      <td>197</td>\n",
       "      <td>4655</td>\n",
       "      <td>12626</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-03-14 13:39:43</td>\n",
       "      <td>The most recent vaccine data from Israel: #Pfi...</td>\n",
       "      <td>['PfizerBioNTech', 'vaccine']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7141</th>\n",
       "      <td>1371092387485904907</td>\n",
       "      <td>Ich bins</td>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Die Dummheit der Einen ist die Macht der Ander...</td>\n",
       "      <td>2018-10-31 12:44:46</td>\n",
       "      <td>523</td>\n",
       "      <td>223</td>\n",
       "      <td>71802</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-03-14 13:34:33</td>\n",
       "      <td>So ist es‚ÄºÔ∏è\\n#impfschaden #Impftote #PfizerBio...</td>\n",
       "      <td>['impfschaden', 'Impftote', 'PfizerBiontech', ...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7142</th>\n",
       "      <td>1371089216680120326</td>\n",
       "      <td>Rebecca VanderMeulen</td>\n",
       "      <td>Downingtown, PA/Wilmington, DE</td>\n",
       "      <td>High school counselor. Part-time recovering jo...</td>\n",
       "      <td>2008-10-02 17:51:46</td>\n",
       "      <td>889</td>\n",
       "      <td>1114</td>\n",
       "      <td>760</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-03-14 13:21:57</td>\n",
       "      <td>One shot down! #CovidVaccine #PfizerBioNTech h...</td>\n",
       "      <td>['CovidVaccine', 'PfizerBioNTech']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7143</th>\n",
       "      <td>1371082512181686272</td>\n",
       "      <td>News.Az</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-01-07 13:02:06</td>\n",
       "      <td>4127</td>\n",
       "      <td>268</td>\n",
       "      <td>270</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-03-14 12:55:19</td>\n",
       "      <td>Stopping #vaccine deliveries to #Azerbaijan is...</td>\n",
       "      <td>['vaccine', 'Azerbaijan', 'Israeli', 'Azerbaij...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7144</th>\n",
       "      <td>1371077764829347842</td>\n",
       "      <td>DIF üá™üá∫</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Health is not everything, but without health,...</td>\n",
       "      <td>2020-08-07 21:41:59</td>\n",
       "      <td>50</td>\n",
       "      <td>581</td>\n",
       "      <td>4947</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-03-14 12:36:27</td>\n",
       "      <td>#AstraZeneca is safe. Believe the statistics, ...</td>\n",
       "      <td>['AstraZeneca']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7145 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id             user_name  \\\n",
       "0     1340539111971516416            Rachel Roh   \n",
       "1     1338158543359250433           Albert Fong   \n",
       "2     1337858199140118533              eliüá±üáπüá™üá∫üëå   \n",
       "3     1337855739918835717         Charles Adler   \n",
       "4     1337854064604966912  Citizen News Channel   \n",
       "...                   ...                   ...   \n",
       "7140  1371093686088568837        Oezguer Yalcin   \n",
       "7141  1371092387485904907              Ich bins   \n",
       "7142  1371089216680120326  Rebecca VanderMeulen   \n",
       "7143  1371082512181686272               News.Az   \n",
       "7144  1371077764829347842                DIF üá™üá∫   \n",
       "\n",
       "                       user_location  \\\n",
       "0          La Crescenta-Montrose, CA   \n",
       "1                  San Francisco, CA   \n",
       "2                           Your Bed   \n",
       "3             Vancouver, BC - Canada   \n",
       "4                                NaN   \n",
       "...                              ...   \n",
       "7140                             NaN   \n",
       "7141                     Deutschland   \n",
       "7142  Downingtown, PA/Wilmington, DE   \n",
       "7143                      Azerbaijan   \n",
       "7144                             NaN   \n",
       "\n",
       "                                       user_description         user_created  \\\n",
       "0     Aggregator of Asian American news; scanning di...  2009-04-08 17:52:46   \n",
       "1     Marketing dude, tech geek, heavy metal & '80s ...  2009-09-21 15:27:30   \n",
       "2                                        heil, hydra üñê‚ò∫  2020-06-25 23:30:28   \n",
       "3     Hosting \"CharlesAdlerTonight\" Global News Radi...  2008-09-10 11:28:53   \n",
       "4     Citizen News Channel bringing you an alternati...  2020-04-23 17:58:42   \n",
       "...                                                 ...                  ...   \n",
       "7140  Philosophy, public health\\nPerspectives on #SA...  2021-01-12 10:38:24   \n",
       "7141  Die Dummheit der Einen ist die Macht der Ander...  2018-10-31 12:44:46   \n",
       "7142  High school counselor. Part-time recovering jo...  2008-10-02 17:51:46   \n",
       "7143                                                NaN  2010-01-07 13:02:06   \n",
       "7144  \"Health is not everything, but without health,...  2020-08-07 21:41:59   \n",
       "\n",
       "      user_followers  user_friends  user_favourites  user_verified  \\\n",
       "0                405          1692             3247          False   \n",
       "1                834           666              178          False   \n",
       "2                 10            88              155          False   \n",
       "3              49165          3933            21853           True   \n",
       "4                152           580             1473          False   \n",
       "...              ...           ...              ...            ...   \n",
       "7140             197          4655            12626          False   \n",
       "7141             523           223            71802          False   \n",
       "7142             889          1114              760          False   \n",
       "7143            4127           268              270          False   \n",
       "7144              50           581             4947          False   \n",
       "\n",
       "                     date                                               text  \\\n",
       "0     2020-12-20 06:06:44  Same folks said daikon paste could treat a cyt...   \n",
       "1     2020-12-13 16:27:13  While the world has been on the wrong side of ...   \n",
       "2     2020-12-12 20:33:45  #coronavirus #SputnikV #AstraZeneca #PfizerBio...   \n",
       "3     2020-12-12 20:23:59  Facts are immutable, Senator, even when you're...   \n",
       "4     2020-12-12 20:17:19  Explain to me again why we need a vaccine @Bor...   \n",
       "...                   ...                                                ...   \n",
       "7140  2021-03-14 13:39:43  The most recent vaccine data from Israel: #Pfi...   \n",
       "7141  2021-03-14 13:34:33  So ist es‚ÄºÔ∏è\\n#impfschaden #Impftote #PfizerBio...   \n",
       "7142  2021-03-14 13:21:57  One shot down! #CovidVaccine #PfizerBioNTech h...   \n",
       "7143  2021-03-14 12:55:19  Stopping #vaccine deliveries to #Azerbaijan is...   \n",
       "7144  2021-03-14 12:36:27  #AstraZeneca is safe. Believe the statistics, ...   \n",
       "\n",
       "                                               hashtags               source  \\\n",
       "0                                    ['PfizerBioNTech']  Twitter for Android   \n",
       "1                                                   NaN      Twitter Web App   \n",
       "2     ['coronavirus', 'SputnikV', 'AstraZeneca', 'Pf...  Twitter for Android   \n",
       "3                                                   NaN      Twitter Web App   \n",
       "4        ['whereareallthesickpeople', 'PfizerBioNTech']   Twitter for iPhone   \n",
       "...                                                 ...                  ...   \n",
       "7140                      ['PfizerBioNTech', 'vaccine']      Twitter Web App   \n",
       "7141  ['impfschaden', 'Impftote', 'PfizerBiontech', ...      Twitter Web App   \n",
       "7142                 ['CovidVaccine', 'PfizerBioNTech']  Twitter for Android   \n",
       "7143  ['vaccine', 'Azerbaijan', 'Israeli', 'Azerbaij...      Twitter Web App   \n",
       "7144                                    ['AstraZeneca']   Twitter for iPhone   \n",
       "\n",
       "      retweets  favorites  is_retweet  \n",
       "0            0          0       False  \n",
       "1            1          1       False  \n",
       "2            0          0       False  \n",
       "3          446       2129       False  \n",
       "4            0          0       False  \n",
       "...        ...        ...         ...  \n",
       "7140         3          3       False  \n",
       "7141         1          2       False  \n",
       "7142         0          2       False  \n",
       "7143         1          2       False  \n",
       "7144         0          2       False  \n",
       "\n",
       "[7145 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pd.read_csv(\"vaccination_tweets.csv\", usecols = [8,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LE = LabelEncoder()\n",
    "messages['target'] = LE.fit_transform(messages[\"user_verified\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = messages['text']\n",
    "y = messages['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english') + list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = stopwords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = vectorizer.fit_transform(X_train)\n",
    "tf_idf_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tropical'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_test_df = pd.DataFrame(tf_idf_test.toarray(), columns=vectorizer.vocabulary_.keys())\n",
    "first_doc = tf_idf_test_df.loc[0]\n",
    "first_doc.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_doc['kill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"you're\", 'as', \"should've\", \"you'll\", 'you', \"you'd\", 'am', 'hasn', 'our', 'under', 'this', 'by', \"that'll\", 'for', 'own', 'while', 'its', 'who', 'i', 'itself', \"you've\", 't', 'off', 'during', \"needn't\", 'what', 'haven', 'wouldn', 'above', 'y', 'all', 'any', 'needn', 'if', 'yourself', 'was', 'ours', \"aren't\", 'yourselves', 'hers', 'below', 'it', 'he', 'mightn', 'only', 'yours', 'same', \"doesn't\", \"mustn't\", 'up', 'll', 'been', 'here', 'the', 'or', 'then', 'don', 'ourselves', 'nor', 'now', 'theirs', 'won', 'has', 'having', 'we', 've', \"didn't\", \"mightn't\", 'shan', 'did', 'before', 'too', 'wasn', 'most', 'no', 'a', 'with', 'such', 'shouldn', 'out', 'other', 'those', 'themselves', 'to', 'my', 'ain', \"she's\", 'that', \"isn't\", 'myself', 'me', 'between', 'can', \"won't\", 'them', 'does', 'at', \"couldn't\", 'weren', 'there', 'after', 'himself', 'whom', 'an', 'doesn', \"haven't\", \"shan't\", 'not', 'once', \"it's\", 'through', 'and', 'had', 'of', 'be', 'mustn', 'your', 'again', 'couldn', 'is', 'some', 'being', 'about', 'so', 'should', 'were', 'just', 'd', \"wasn't\", 'their', 'these', 'doing', 's', 'each', 'few', 'herself', 'further', 'when', 'o', 'until', 'him', 'in', 'why', 'more', 'didn', 'how', 'over', 'will', 'than', \"don't\", 'do', 'because', 'ma', 'hadn', 'both', \"weren't\", 'against', 'on', 'his', 'her', 'are', 'isn', \"wouldn't\", 're', 'have', 'into', 'where', 'but', 'm', 'they', 'she', 'from', 'very', 'which', \"hasn't\", 'aren', 'down', \"shouldn't\", \"hadn't\"}\n"
     ]
    }
   ],
   "source": [
    "stop_words=set(stopwords.words(\"english\"))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "\n",
    "#tokenized_review = tokenizer.tokenize(messages['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegexpTokenizer(pattern='[a-zA-Z0-9]+', gaps=False, discard_empty=True, flags=re.UNICODE|re.MULTILINE|re.DOTALL)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"Hi what is up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi what is up'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['tokenizer'] = messages['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['tokenizer'] = messages['tokenizer'].map(lambda x: tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## messages['filtered_tokenizer'] = messages['tokenizer'].apply(lambda x: x.append if x[i] not in stop_words for i in range(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = messages.apply(lambda x: x.str.strip() if x.dtypes == 'object' else x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
